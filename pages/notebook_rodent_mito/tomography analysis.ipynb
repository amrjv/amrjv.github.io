{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G56Bglu_OiwN"
   },
   "source": [
    "# Segmentation and Visualisation of Rodent Mitochondria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUOuBWt4OiwS"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuqvQeiqOiwa"
   },
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inu9b0VXOiwb"
   },
   "source": [
    "The purpose of this notebook is to go through some automated analysis processes of morphology one might want to measure during a typical study of mitochondria\n",
    "\n",
    "This notebook draws upon literature from the following sources for analysis: \n",
    "\n",
    "    Vincent et al. Cell Reports 26, 996–1009, January 22, 2019\n",
    "    Lucchi et al. IEEE Transactions on Medical Imaging. 2015.\n",
    "    Luchhi et al. CVPR, Portland, Oregon, USA, June 23}-28, 2013\n",
    "    Belevich et al. PLOS Biology | DOI:10.1371/journal.pbio.1002340\n",
    "\n",
    "The dataset can be downloaded from: https://cvlab.epfl.ch/research/page-90578-en-html/research-medical-em-mitochondria-index-php/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_B_5pWPeOiwc"
   },
   "source": [
    "### Some context \n",
    "Morphological changes caused by genetic and biochemical mitochondrial funcion defects are a major cause of human disease. Mitochondria are subject to continious morphological changes over time. Therefore quantifying these parameters in an automated manner at high throughput is key in understanding mitochondrial diseases. \n",
    "\n",
    "One of the approaches to measure these morphological changes at high resolution is by using serial block face scanning electron microscopy. More information about this technique can be found in the link: https://en.wikipedia.org/wiki/Serial_block-face_scanning_electron_microscopy. \n",
    "\n",
    "In short, this technique slices the samples into sections using an ultramicrotome and preiodically records a scanning electron microscope image. The images can be stacked together to obtain a 3D reconstruction of the microtomed region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJ-kzMmISbUM"
   },
   "source": [
    "### Downloading the dataset from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0pgJZoFSaLd"
   },
   "outputs": [],
   "source": [
    "#taken from this StackOverflow answer: https://stackoverflow.com/a/39225039\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_te0la2Sja2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# link to download the pretrained CNN model\n",
    "file_id = '1PUkTh6atShukHKYDqOrd-TYEFRS73hff'\n",
    "destination = os.path.join(os.getcwd(),'model.h5')\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "print(\"downloaded the model\")\n",
    "\n",
    "\n",
    "# link to download the volumetric data https://drive.google.com/file/d/1JM-AUC5pikeaYMrALmGKMjpY5fcux4tO/view?usp=sharing\n",
    "file_id = '1JM-AUC5pikeaYMrALmGKMjpY5fcux4tO'\n",
    "destination = os.path.join(os.getcwd(),'volumedata.tif')\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "print(\"downloaded the fib data\")\n",
    "\n",
    "# link to download the training dataset https://drive.google.com/file/d/1u6Ut_BJ4VBeJw8zn13NDjPErGDRbAZsQ/view?usp=sharing\n",
    "file_id = '1u6Ut_BJ4VBeJw8zn13NDjPErGDRbAZsQ'\n",
    "destination = os.path.join(os.getcwd(),'training.tif')\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "print(\"downloaded the training data\")\n",
    "\n",
    "\n",
    "#link to download the test dataset https://drive.google.com/file/d/1RiMNJxa8TK1MTHdL-xY-sx_w_x3WQxct/view?usp=sharing\n",
    "file_id = '1RiMNJxa8TK1MTHdL-xY-sx_w_x3WQxct'\n",
    "destination = os.path.join(os.getcwd(),'training_groundtruth.tif')\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "print(\"downloaded the ground truth\")\n",
    "\n",
    "#link to download the test dataset https://drive.google.com/file/d/1hX6-kNG_6N_p7330slD-jNpM2i59Jc_G/view?usp=sharing\n",
    "file_id = '1hX6-kNG_6N_p7330slD-jNpM2i59Jc_G'\n",
    "destination = os.path.join(os.getcwd(),'testing.tif')\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "print(\"downloaded the testing data\")\n",
    "\n",
    "#link to download the test dataset https://drive.google.com/file/d/1XFovvC_d7NK7Xi0xhndp7ng40GlJa8Z_/view?usp=sharing\n",
    "file_id = '1XFovvC_d7NK7Xi0xhndp7ng40GlJa8Z_'\n",
    "destination = os.path.join(os.getcwd(),'testing_groundtruth.tif')\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "print(\"downloaded the testing ground truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTRmmuMX7KTj"
   },
   "source": [
    "![alt text](https://assets.datacamp.com/production/repositories/3981/datasets/b22fa4767f979b26b193faa2cf166adde3d6cf54/Screen%20Shot%202019-01-19%20at%202.53.18%20PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWIx7SHROiwd"
   },
   "source": [
    "### The dataset of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meXFMgLIOiwe"
   },
   "source": [
    "The image stack represents a 5x5x5µm section taken from the CA1 hippocampus region of the brain, corresponding to a 1065x2048x1536 volume with a voxel resolution of ~5nm. \n",
    "\n",
    "We can visualise this dataset along the x, y and z directions as a function of depth within the sample as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJz7qmltOiwh"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "dataset3D = imread('volumedata.tif') # read the tiff image stack\n",
    "print(dataset3D.shape) # check the image stack shape to see whether it loaded properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EhCn43nuPYk"
   },
   "source": [
    "Visualisation of the 3D dataset from the  publication: https://www.sciencedirect.com/science/article/pii/S0968432814000250\n",
    "\n",
    "![alt text](https://ars.els-cdn.com/content/image/1-s2.0-S0968432814000250-gr1.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWUzapS2Oiwk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pixel_width = 5 # stated in the dataset record \n",
    "pixel_units = 'nm'\n",
    "\n",
    "nseg = 7 # splitting the dataset into 7 segments for viewing\n",
    "segsx = np.arange(0,dataset3D.shape[0],int(dataset3D.shape[0]/nseg))\n",
    "segsy = np.arange(0,dataset3D.shape[1],int(dataset3D.shape[1]/nseg))\n",
    "segsz = np.arange(0,dataset3D.shape[2],int(dataset3D.shape[2]/nseg))\n",
    "segs = np.ravel(np.asarray([segsx,segsy,segsz]))\n",
    "\n",
    "# plotting all 7 segments along x y and z direction\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(1,22):\n",
    "    plt.subplot(3,7,i)\n",
    "    if i < 8:\n",
    "        plt.title(str(segs[i]*pixel_width)+pixel_units+\" along x\")\n",
    "        plt.imshow(dataset3D[segs[i],:,:],cmap='gray')\n",
    "    if i > 7 and i < 15:\n",
    "        plt.title(str(segs[i]*pixel_width)+pixel_units+\" along y\")\n",
    "        plt.imshow(dataset3D[:,segs[i],:],cmap='gray')\n",
    "    if i > 14:\n",
    "        plt.title(str(segs[i]*pixel_width)+pixel_units+\" along z\")\n",
    "        plt.imshow(dataset3D[:,:,segs[i]],cmap='gray')        \n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('tomographs.png',dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-pN-PRrOiwm"
   },
   "source": [
    "### Segmentation of the dataset.\n",
    "To obtain quantitative information for the sample, the mitochondria need to be segmented from the images. There are numerous freeware and commercial packes to perform segmentation such as ImageJ, Amira, BioImageXD etc... \n",
    "\n",
    "However most packages have either sub-optimal segmentation routines, or require files in proprietary form or have laborious and time consuming workflows. Because of this, recent efforts have been geared towards building computer vision models to identify and segment images using deep learning.\n",
    "\n",
    "For this very purpose, challenges such as ImageNet have emerged and demonstrate the capabilities of of the aforementioned method in comparison with other methods based on support vector machines, Markov models etc. \n",
    "\n",
    "For further reading please refer to the publication here: https://arxiv.org/ftp/arxiv/papers/1605/1605.09612.pdf\n",
    "\n",
    "For this dataset a simple U-Net architecture (called this because the network resembls a U shape) is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMFAP4X4Oiwn"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# defining the different convolutional blocks\n",
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "#defining the unet model\n",
    "def UNet(image_size):\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "\n",
    "    inputs = keras.layers.Input((image_size, image_size, 1))\n",
    "    s = keras.layers.Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "    p0 = s\n",
    "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3]) #16->8\n",
    "\n",
    "    bn = bottleneck(p4, f[4])\n",
    "\n",
    "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
    "\n",
    "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIcDWxfWr66K"
   },
   "source": [
    "![alt text](http://meetshah1995.github.io/images/blog/ss/grfnet.png)\n",
    "\n",
    "Example of a GFR-Net architecture https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJmHMPKpOiwq"
   },
   "outputs": [],
   "source": [
    "model = UNet(256) #create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boDS64dmOiws"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMKt9b-3Xrk7"
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.h5') # to speed up training lets use weights from a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pkxk5iNiOiwv"
   },
   "source": [
    "The model can be visualised using Kera's plot_model function as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i7b0PxpOiww",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model,to_file='model.png') # plot the model \n",
    "plt.figure(figsize=(5,1),dpi=700)\n",
    "plt.imshow(np.rot90(imread('model.png')))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6IuB6ErOiwz"
   },
   "source": [
    "To train this model to 'learn' where the mitochondria are within the images, a few requirements must be met. \n",
    "1. A set of training data with annotated labels is required\n",
    "2. The training dataset should be generalised in order for the model to be robust when making predictions on 'live' or validation data.\n",
    "\n",
    "There are also other requirements such as the model should not overfit ot how the model should deal with sub-classes belonging to multiple datasets or even the ampunt of data needed to train the model. A comprehensive list of these can be found at: https://ti.arc.nasa.gov/m/pub-archive/archive/0473.pdf\n",
    "\n",
    "For this dataset a set of training and validation data was generously provided by https://cvlab.epfl.ch/research/page-90578-en-html/research-medical-em-mitochondria-index-php/.\n",
    "\n",
    "Some of the visualisations of the training and testing data are provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0LjONyEFOiw0"
   },
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "\n",
    "X_train = imread('training.tif')\n",
    "y_train = imread('training_groundtruth.tif')\n",
    "X_test  = imread('testing.tif')\n",
    "y_test  = imread('testing_groundtruth.tif')\n",
    "\n",
    "np.random.seed(47) # fixing the seed for reproducibility\n",
    "idx = np.random.randint(0,X_train.shape[0]-1,10)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle(\"Training images selected at random\",fontsize=32)\n",
    "for i in range(0,10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(label2rgb(y_train[idx[i]],X_train[idx[i]]),\n",
    "               alpha=0.7)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_data.png',dpi=100)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle(\"Testing images selected at random\",fontsize=32)\n",
    "for i in range(0,10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(label2rgb(y_test[idx[i]],X_test[idx[i]]),\n",
    "               alpha=0.7)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_data.png',dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tk-PKltbOiw3"
   },
   "source": [
    "To train the UNet model with this data, the images and labels need to be resized into 1x256x256 (this is the input the model was designed to accept). \n",
    "\n",
    "After the data has been resized, the data can be used as an input for the UNet model. However in some cases it is useful to 'augment' the data to improve the models ability to generalise to problems. \n",
    "\n",
    "More details in data augmentation can be found at: https://openreview.net/pdf?id=rkBBChjiG\n",
    "\n",
    "For this dataset some simple augmentations were applied at random. These were: Gaussian Blurring, Gaussian Noise, Contrast Normalisation, Addition and Subtraction of intensities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ni31of-Oiw4"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "X_train_resized = np.zeros((X_train.shape[0],256,256,1),dtype='uint8')\n",
    "y_train_resized = np.zeros((y_train.shape[0],256,256,1),dtype='bool')\n",
    "X_test_resized  = np.zeros((X_test.shape[0],256,256,1),dtype='uint8')\n",
    "y_test_resized  = np.zeros((y_test.shape[0],256,256,1),dtype='bool')\n",
    "\n",
    "#resizing the dataset\n",
    "for i in tqdm(range(0,X_train.shape[0])):\n",
    "    X_train_resized[i] = resize(X_train[i],(256,256,1),mode='constant',preserve_range=True)\n",
    "    y_train_resized[i] = resize(y_train[i],(256,256,1),mode='constant',preserve_range=True)\n",
    "    X_test_resized[i] = resize(X_test[i],(256,256,1),mode='constant',preserve_range=True)\n",
    "    y_test_resized[i] = resize(y_test[i],(256,256,1),mode='constant',preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxaVtB_jOiw7"
   },
   "outputs": [],
   "source": [
    "# applying augmentations to the dataset \n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def augment_dataset(X,y):\n",
    "    sometimes = lambda aug: iaa.Sometimes(1, aug) # e.g. Sometimes(0.5, ...) applies the given augmenter in 50% of all cases\n",
    "    seq = iaa.Sequential([\n",
    "        sometimes(iaa.GaussianBlur(sigma=(0, 0.3))), # blur images with a sigma of 0 to 3.0\n",
    "        sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
    "        sometimes(iaa.AdditivePoissonNoise()),\n",
    "        sometimes(iaa.ContrastNormalization((0.5, 2.0))),\n",
    "        sometimes(iaa.Add((-10, 10))),\n",
    "    ],random_order=True)\n",
    "    return shuffle(np.concatenate((X,seq.augment_images(X))),\n",
    "           np.concatenate((y,y)),random_state=42)\n",
    "    \n",
    "X_train_augmented, y_train_augmented = augment_dataset(X_train_resized,y_train_resized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YS-Die1EOiw-"
   },
   "outputs": [],
   "source": [
    "# visualising the augmentations\n",
    "idx = np.random.randint(0,X_train_augmented.shape[0]-1,10)\n",
    "\n",
    "plt.figure(figsize=(12.5,7))\n",
    "plt.suptitle(\"Augmented - Training images selected at random\",fontsize=32)\n",
    "for i in range(0,10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(label2rgb(y_train_augmented[idx[i],:,:,0],X_train_augmented[idx[i],:,:,0]),\n",
    "               alpha=0.7)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_data.png',dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nlFWEBHOixA"
   },
   "source": [
    "When evaluating a standard machine learning model, we usually classify our predictions into four categories: true positives, false positives, true negatives, and false negatives. However, for the dense prediction task of image segmentation, it's not immediately clear what counts as a \"true positive\" and, more generally, how we can evaluate our predictions? we define an intersect over union metric. https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n",
    "This is basically an overlap test to benchmark the models performance. Finally, with all the ingredients in place the model can be trained on the augmented dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oaPV6ZeOixB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-mitochondria.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_J1Dgh7OixD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create new tensorboard logs. call \"tensorboard --logdir logs/fit\" to view logs\n",
    "import datetime\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(X_train_augmented,y_train_augmented,\n",
    "          validation_split=0.1,\n",
    "          batch_size=8,\n",
    "          epochs=1,\n",
    "          callbacks=[earlystopper, checkpointer, tensorboard_callback]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNn7D1PqwlnA"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAvRh5-0xdgz"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jF8k0XoMOixF"
   },
   "outputs": [],
   "source": [
    "# plotting the accuracy and loss of the model over time\n",
    "# import plotly objects and generate the graphs in offline mode\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "def enable_plotly_in_cell():\n",
    "  import IPython\n",
    "  from plotly.offline import init_notebook_mode\n",
    "  display(IPython.core.display.HTML('''<script src=\"/static/components/requirejs/require.js\"></script>'''))\n",
    "  init_notebook_mode(connected=False)\n",
    "\n",
    "enable_plotly_in_cell()\n",
    "\n",
    "epochs = np.linspace(0,len(model.history.history['loss']),len(model.history.history['loss'])+1)\n",
    "loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "mean_iou = model.history.history['mean_iou']\n",
    "val_mean_iou = model.history.history['val_mean_iou']\n",
    "\n",
    "trace1 = go.Scatter(x=epochs,y=loss,name=\"loss\")\n",
    "trace2 = go.Scatter(x=epochs,y=val_loss,name=\"validation loss\")\n",
    "trace3 = go.Scatter(x=epochs,y=mean_iou,name=\"mean iou\")\n",
    "trace4 = go.Scatter(x=epochs,y=val_mean_iou,name=\"validation mean iou\")\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=2)\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 1)\n",
    "fig.append_trace(trace3, 1, 2)\n",
    "fig.append_trace(trace4, 1, 2)\n",
    "fig['layout'].update(height=400, \n",
    "                     width=900, \n",
    "                     title='Comparison of training and validation progress with increasing epochs')\n",
    "fig['layout']['xaxis1'].update(title='epoch')\n",
    "fig['layout']['xaxis2'].update(title='epoch')\n",
    "fig['layout']['yaxis1'].update(title='loss')\n",
    "fig['layout']['yaxis2'].update(title='mean iou')\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQ1L481SOixH"
   },
   "source": [
    "The graphs above show that the mean intersection metric caps out at ~>0.8 in the validaiton test.To improve the metric, there are several ways to update the model from here to increase accuracy. But in this case we want to check this simple model's performance on the testing data by visualising the hand segmented labels against the trained model's predictions. The output from the model can be interpreted as a probability map of how confident the model is at assigning the pixels belonging to the mitochondria. For this a probability >0.5 was chosen as the threshold for classifying mitochondria pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9zWv_bdOixI"
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_resized,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZusBVsKbOixK"
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(0,y_test_pred.shape[0]-1,5)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.suptitle(\"Predictions from the model\",fontsize=32)\n",
    "for i in range(0,5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(label2rgb(y_test_pred[idx[i],:,:,0]>0.5,X_test_resized[idx[i],:,:,0]),alpha=0.7)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.suptitle(\"Manually segmented labels\",fontsize=32)\n",
    "for i in range(0,5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(label2rgb(y_test_resized[idx[i],:,:,0]>0.5,X_test_resized[idx[i],:,:,0]),alpha=0.7)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gB6-o3WBOixO"
   },
   "source": [
    "A comparison of the model against the manually segmented data shows that the model still needs refining in classifying the mitochondria in some regions of the images. Some popular methods to improve the segmentation are to introduce more relevant augmentations, addition of data with false positives, adding dropout layers in the model for generalisation, using a more sophisticated model etc. \n",
    "\n",
    "As the results look sensible for this specific case, the model can be used to segment the three dimensional dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_ATdn0nOixP"
   },
   "source": [
    "### Three dimensional segmentation of the ultra microtome section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgtHoP5DOixR"
   },
   "outputs": [],
   "source": [
    "#prep 3D data for the model to make predictions\n",
    "def prepare_3Ddata(array3D,imw,imh):\n",
    "    if array3D.dtype=='bool':\n",
    "        data = np.zeros((array3D.shape[2],imw,imh,1),dtype='bool')\n",
    "    else:\n",
    "        data = np.zeros((array3D.shape[2],imw,imh,1),dtype='uint8')\n",
    "    for i in tqdm(range(0,data.shape[0])):\n",
    "        data[i] = resize(array3D[:,:,i],(imw,imh,1),mode='constant',preserve_range=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luIQuzH1OixU"
   },
   "outputs": [],
   "source": [
    "dataset3D_resized = prepare_3Ddata(dataset3D,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHd-n8CDOixX"
   },
   "outputs": [],
   "source": [
    "dataset3D_pred = model.predict(dataset3D_resized,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuh08OHwOixZ"
   },
   "outputs": [],
   "source": [
    "dataset3D_pred_resized = np.zeros((dataset3D.shape[0],\n",
    "                                   dataset3D.shape[1],\n",
    "                                   dataset3D.shape[2]),dtype='bool')\n",
    "\n",
    "for i in tqdm(range(0,dataset3D_pred_resized.shape[0])):\n",
    "    dataset3D_pred_resized[:,:,i] = resize(dataset3D_pred[i,:,:,0]>0.5,\n",
    "                                          (dataset3D.shape[0],dataset3D.shape[1]),\n",
    "                                           preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNs2A24cOixb"
   },
   "outputs": [],
   "source": [
    "nseg = 7 # splitting the dataset into 7 segments for viewing\n",
    "segsx = np.arange(0,dataset3D.shape[0],int(dataset3D.shape[0]/nseg))\n",
    "segsy = np.arange(0,dataset3D.shape[1],int(dataset3D.shape[1]/nseg))\n",
    "segsz = np.arange(0,dataset3D.shape[2],int(dataset3D.shape[2]/nseg))\n",
    "segs = np.ravel(np.asarray([segsx,segsy,segsz]))\n",
    "\n",
    "# plotting all 7 segments along x y and z direction\n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(1,22):\n",
    "    plt.subplot(3,7,i)\n",
    "    if i < 8:\n",
    "        plt.title(str(segs[i]*pixel_width)+pixel_units+\" along x\")\n",
    "        plt.imshow(label2rgb(dataset3D_pred_resized[segs[i],:,:],dataset3D[segs[i],:,:]),\n",
    "                   alpha=0.7,cmap='gray')\n",
    "    if i > 7 and i < 15:\n",
    "        plt.title(str(segs[i]*pixel_width)+pixel_units+\" along y\")\n",
    "        plt.imshow(label2rgb(dataset3D_pred_resized[:,segs[i],:],dataset3D[:,segs[i],:]),\n",
    "                   alpha=0.7,cmap='gray')\n",
    "    if i > 14:\n",
    "        plt.title(str(segs[i]*pixel_width)+pixel_units+\" along z\")\n",
    "        plt.imshow(label2rgb(dataset3D_pred_resized[:,:,segs[i]],dataset3D[:,:,segs[i]]),\n",
    "                   alpha=0.7,cmap='gray')        \n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('tomographs_labelled.png',dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aB0LcWnuOixc"
   },
   "outputs": [],
   "source": [
    "#clearing redundant variables and cleaning up variable space\n",
    "import gc\n",
    "gc.collect()\n",
    "del dataset3D_resized, y_test_resized, X_test_resized, \n",
    "del X_train, y_train, X_test, y_test, y_train_augmented, X_train_augmented\n",
    "del dataset3D_pred\n",
    "dataset3D_pred_resized = dataset3D_pred_resized.astype('int8')\n",
    "del dataset3D\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQGZU8PfOixe"
   },
   "source": [
    "After making the predictions, the data cube can be visualised with 3D meshing using a fast marching algorithm. The 3D results of the segmentation are shown below using an interactive plotly figure. The data has been rebinned by a factor of ~24 to reduce the file size and maintain webpage stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fR7VnHpCOixf"
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "vertices, faces, normals, values = measure.marching_cubes_lewiner(dataset3D_pred_resized,\n",
    "                                                                  step_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzUvsM9NOixh"
   },
   "outputs": [],
   "source": [
    "enable_plotly_in_cell()\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "x,y,z = zip(*vertices)  \n",
    "fig = ff.create_trisurf(x=x,y=y,z=z,simplices=faces)\n",
    "fig['layout'] = dict(\n",
    "         title=\"Mitochondria ISO-surface binned by a factor of 12\", \n",
    "         font=dict(family='Balto'),\n",
    "         showlegend=False,\n",
    "         width=900,\n",
    "         height=900,\n",
    "         scene=dict(aspectratio=dict(x=dataset3D_pred_resized.shape[0]/dataset3D_pred_resized.shape[2],\n",
    "                                     y=dataset3D_pred_resized.shape[1]/dataset3D_pred_resized.shape[2], \n",
    "                                     z=dataset3D_pred_resized.shape[2]/dataset3D_pred_resized.shape[2])\n",
    "                    )\n",
    "        )\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCf7wZw4Oixl"
   },
   "source": [
    "### Measuring properties from the datacube. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4U03Nc6WOixm"
   },
   "source": [
    "After model segmentation and visualisation, quantitative size and shape information can be obtained from the sample.\n",
    "The following measurements can be performed straight forwardly: \n",
    "1. Volume\n",
    "2. Closest nearest neighbours\n",
    "3. Sphericity (Circularity)\n",
    "4. Eccentricity\n",
    "5. Diameter (or radius)\n",
    "\n",
    "A future post will explore how to measure these properties for tomography datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU8fY1O4Oixm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tomography analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python Intel",
   "language": "python",
   "name": "idp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
